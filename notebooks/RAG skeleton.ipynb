{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10965686,"sourceType":"datasetVersion","datasetId":612177}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install arxiv langchain langchain-community torch transformers pillow datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:01:44.212059Z","iopub.execute_input":"2025-03-12T11:01:44.212243Z","iopub.status.idle":"2025-03-12T11:01:56.869851Z","shell.execute_reply.started":"2025-03-12T11:01:44.212224Z","shell.execute_reply":"2025-03-12T11:01:56.868946Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting arxiv\n  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\nCollecting langchain-community\n  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting feedparser~=6.0.10 (from arxiv)\n  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.10/dist-packages (from arxiv) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.12)\nCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.25)\nRequirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\nRequirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.11.0a2)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\nCollecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n  Downloading langchain_core-0.3.44-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain\n  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2,>=1.22.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.29.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2,>=1.22.4->langchain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.22.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2,>=1.22.4->langchain) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\nDownloading arxiv-2.1.3-py3-none-any.whl (11 kB)\nDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\nDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.44-py3-none-any.whl (415 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.7/415.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\nDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\nDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: sgmllib3k\n  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=739354c44f99f394022ad65062a73f346d1436f0836f18236bbd7ca25e369759\n  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\nSuccessfully built sgmllib3k\nInstalling collected packages: sgmllib3k, python-dotenv, httpx-sse, feedparser, async-timeout, arxiv, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: async-timeout\n    Found existing installation: async-timeout 5.0.1\n    Uninstalling async-timeout-5.0.1:\n      Successfully uninstalled async-timeout-5.0.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.25\n    Uninstalling langchain-core-0.3.25:\n      Successfully uninstalled langchain-core-0.3.25\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.3\n    Uninstalling langchain-text-splitters-0.3.3:\n      Successfully uninstalled langchain-text-splitters-0.3.3\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.12\n    Uninstalling langchain-0.3.12:\n      Successfully uninstalled langchain-0.3.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed arxiv-2.1.3 async-timeout-4.0.3 feedparser-6.0.11 httpx-sse-0.4.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.44 langchain-text-splitters-0.3.6 pydantic-settings-2.8.1 python-dotenv-1.0.1 sgmllib3k-1.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install pymupdf faiss-cpu PyMuPDF requests","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:01:56.870812Z","iopub.execute_input":"2025-03-12T11:01:56.871153Z","iopub.status.idle":"2025-03-12T11:02:03.506994Z","shell.execute_reply.started":"2025-03-12T11:01:56.871119Z","shell.execute_reply":"2025-03-12T11:02:03.506176Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf, faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0 pymupdf-1.25.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Step 1: Implement a Basic Text-Based RAG Model Using LangChain\n\n# Import necessary libraries\nimport arxiv\nimport os\nimport requests\nimport json\nfrom langchain.document_loaders import ArxivLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings  # Use Hugging Face for embeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import HuggingFacePipeline  # Use Hugging Face for text generation\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM  # For Hugging Face models\nimport torch\nimport fitz\nfrom PIL import Image\nfrom transformers import CLIPProcessor, CLIPModel, WhisperProcessor, WhisperForConditionalGeneration","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:02:09.354897Z","iopub.execute_input":"2025-03-12T11:02:09.355292Z","iopub.status.idle":"2025-03-12T11:02:31.208596Z","shell.execute_reply.started":"2025-03-12T11:02:09.355251Z","shell.execute_reply":"2025-03-12T11:02:31.207649Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Hugging_Face_Token\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:02:34.181554Z","iopub.execute_input":"2025-03-12T11:02:34.182242Z","iopub.status.idle":"2025-03-12T11:02:34.404282Z","shell.execute_reply.started":"2025-03-12T11:02:34.182209Z","shell.execute_reply":"2025-03-12T11:02:34.403398Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Step 1.1: Collect and Preprocess Text Data\ndef collect_and_preprocess_data(query: str, max_results: int = 10):\n    \"\"\"\n    Collect scientific papers from arXiv based on a query and preprocess the text data.\n    Args:\n        query (str): The search query for arXiv (e.g., \"quantum computing\").\n        max_results (int): Maximum number of papers to retrieve.\n    Returns:\n        List[Document]: A list of preprocessed documents.\n    \"\"\"\n    # Use LangChain's ArxivLoader to fetch papers\n    loader = ArxivLoader(query=query, max_results=max_results)\n    documents = loader.load()\n\n    # Preprocess the text data\n    for doc in documents:\n        # Remove LaTeX formatting \n        doc.page_content = doc.page_content.replace(\"\\\\\", \"\")\n\n        # Remove special characters and stopwords\n        doc.page_content = \" \".join([word for word in doc.page_content.split() if word.isalnum()])\n\n    return documents\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:08:10.617815Z","iopub.execute_input":"2025-03-10T12:08:10.618122Z","iopub.status.idle":"2025-03-10T12:08:10.622982Z","shell.execute_reply.started":"2025-03-10T12:08:10.618098Z","shell.execute_reply":"2025-03-10T12:08:10.621957Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Step 1.2: Set Up LangChain for Text Retrieval\ndef setup_rag_pipeline(documents):\n    \"\"\"\n    Set up a basic RAG pipeline using LangChain and Hugging Face models.\n    Args:\n        documents (List[Document]): Preprocessed documents.\n    Returns:\n        RetrievalQA: A RAG pipeline for querying documents.\n    \"\"\"\n    # Step 1.2.1: Split documents into smaller chunks for better retrieval\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n    texts = text_splitter.split_documents(documents)\n\n    # Step 1.2.2: Generate embeddings for the text chunks using Hugging Face\n    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # Lightweight and efficient embedding model\n    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n    vectorstore = FAISS.from_documents(texts, embeddings)\n\n    # Step 1.2.3: Set up the retriever\n    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})  # Retrieve top 5 most relevant chunks\n\n    # Step 1.2.4: Integrate a Hugging Face language model for text generation\n    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # Use GPT-2 for text generation\n    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n    text_generator = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=100,\n        temperature=0.7\n    )\n    llm = HuggingFacePipeline(pipeline=text_generator)\n\n    # Step 1.2.5: Create the RAG pipeline\n    rag_pipeline = RetrievalQA.from_chain_type(\n        llm=llm,\n        chain_type=\"stuff\",\n        retriever=retriever,\n        return_source_documents=True\n    )\n\n    return rag_pipeline\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:25:07.926477Z","iopub.execute_input":"2025-03-10T12:25:07.926849Z","iopub.status.idle":"2025-03-10T12:25:07.933322Z","shell.execute_reply.started":"2025-03-10T12:25:07.926822Z","shell.execute_reply":"2025-03-10T12:25:07.932231Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Step 1.3: Test the Text-Based RAG Model\ndef test_rag_pipeline(rag_pipeline, query: str):\n    \"\"\"\n    Test the RAG pipeline by querying it with a user question.\n    Args:\n        rag_pipeline (RetrievalQA): The RAG pipeline.\n        query (str): The user's query.\n    \"\"\"\n    # Query the RAG pipeline\n    result = rag_pipeline({\"query\": query})\n\n    # Display the result\n    print(\"Answer:\", result[\"result\"])\n    print(\"\\nSource Documents:\")\n    for doc in result[\"source_documents\"]:\n        print(f\"Document: {doc.metadata['title']}\")\n        print(f\"Content: {doc.page_content[:200]}...\\n\")  # Display first 200 characters\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:25:10.412205Z","iopub.execute_input":"2025-03-10T12:25:10.412533Z","iopub.status.idle":"2025-03-10T12:25:10.417442Z","shell.execute_reply.started":"2025-03-10T12:25:10.412505Z","shell.execute_reply":"2025-03-10T12:25:10.416264Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Main Execution\nif __name__ == \"__main__\":\n    # Step 1.1: Collect and preprocess data\n    query = \"quantum computing\"\n    documents = collect_and_preprocess_data(query, max_results=5)\n\n    # Step 1.2: Set up the RAG pipeline\n    rag_pipeline = setup_rag_pipeline(documents)\n\n    # Step 1.3: Test the RAG pipeline\n    user_query = \"What is quantum computing?\"\n    test_rag_pipeline(rag_pipeline, user_query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:25:12.437781Z","iopub.execute_input":"2025-03-10T12:25:12.438132Z","iopub.status.idle":"2025-03-10T12:25:16.718877Z","shell.execute_reply.started":"2025-03-10T12:25:12.438109Z","shell.execute_reply":"2025-03-10T12:25:16.717601Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\n31 Mar 2000 Unconventional Quantum Computing Devices Seth Lloyd Mechanical Engineering MIT 02139 This paper investigates a variety of unconventional quantum computation including fermionic quantum computers and computers that exploit nonlinear tum It is shown that unconventional quantum computing devices can in ciple compute some quantities more rapidly than quantum Computers are what they can and cannot do is determined by the laws of When scientiﬁc progress augments or revises those our picture of what computers can do quantum mechanics is generally accepted as the fundamental dynamical theory of how physical systems Quantum computers can in principle exploit quantum coherence to perform computational tasks that classical puters cannot If someday quantum mechanics should turn out to be incomplete or then our picture of what computers can do will In the set of known quantum phenomena is constantly essentially any coherent quantum phenomenon involving nonlinear interactions between\n\nincluding early work nearly over two decades Key to performing such control of quantum gates is the use of which can be viewed as a resource for such More recent work has looked at how to partition the computations of distributed quantum circuits over multiple as we mentioned earlier with considerations including distributing computations in such a way as to optimize performance and to reduce the requirements on since if the entanglements required are generated at too low a this will hold up The key motivation here is to a set of quantum computers to form effectively a much more powerful quantum 3 QUANTUM CLOUD COMPUTING AND ING QUANTUM COMPUTATIONS We have seen big tech companies and startups offering quantum computing as a service similar to accessing other cloud service which is a fantastic resource for experimentation and More studies into delegating quantum putation from a client can be either or almost with minimal capability to perform For see For see Buhrman and paper dating\n\nquantum multiple quantum computers on different sites to perform distributed computing with a distributed system of quantum computers quantum processing units at different arriving at the notion of distributed quantum While distributed quantum computing can involve tiple QPUs next to each other or at the same with the quantum one can envision distributed quantum Seng Loke is with the School of Information Deakin see Manuscript received X revised X A qubit is the basic unit of quantum and can be thought of as a or such as an where the two levels are spin up and spin or a where the two states are the vertical polarization and the horizontal Multiple qubits at different sites can share an entangled a superpositon of to be used in distributed computing over nodes geographically far As noted in the idea is the quantum Internet as the ing infrastructure of the Distributed Quantum Computing This article highlights the emerging area of distributed quantum computing over the quantum which we\n\nin the idea is the quantum Internet as the ing infrastructure of the Distributed Quantum Computing This article highlights the emerging area of distributed quantum computing over the quantum which we refer to as quantum Internet the idea of puting using quantumly connected distributed quantum computers over quantum Internet computing is not a new concept in itself but a proposed used here for the collection of topics from an analogy to Internet Internet where one does distributed ing but over distances and distributed tems involve nodes connected via the is at the section of work in distributed computing and the Analogous to Internet one could ask the question of what would be at the intersection of work in distributed quantum computing and work on the quantum which brings us to the notion of quantum Internet while the quantum Internet and distributed tum computing are still nascent research there are at least three key topics which can be considered as relevant to quantum Internet\n\n1 Aug 2022 IEEE IOT X 2022 1 The Rise of Quantum Internet Computing Seng IEEE article highlights quantum Internet computing as referring to distributed quantum computing over the quantum analogous to Internet computing involving distributed computing over the Relevant to quantum Internet computing would be areas of study such as quantum protocols for distributed nodes using quantum information for quantum cloud delegated veriﬁable blind or private and distributed quantum over Index Internet quantum distributed quantum Internet distributed Internet work has been submitted to the IEEE for possible Copyright may be transferred without after which this version may no longer be 1 INTRODUCTION T HERE have been tremendous developments in quantum quantum quantum nications and the quantum and we have seen increased investments and intensive research in quantum computing in recent years The quantum Internet will not necessarily replace the Internet we know and use at least not in the near but\n\nQuestion: What is quantum computing?\nHelpful Answer: The quantum Internet is a new type of computing that will be used to perform the tasks of computing the quantum internet. In the short term it will be an attempt to use the quantum network as a means of computing with a quantum computing network that will also be used to compute the quantum Internet and to further the development of the internet. It will be an attempt to use the quantum network for the transmission of information in a way that can be used as a means of sending or receiving information. The quantum internet\n\nSource Documents:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-133c4f7d89ef>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Step 1.3: Test the RAG pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is quantum computing?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtest_rag_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrag_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-51-d5208baa6429>\u001b[0m in \u001b[0;36mtest_rag_pipeline\u001b[0;34m(rag_pipeline, query)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSource Documents:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_documents\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Document: {doc.metadata['title']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Content: {doc.page_content[:200]}...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Display first 200 characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'title'"],"ename":"KeyError","evalue":"'title'","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"# Step 2.1: Load Metadata\ndef load_metadata(metadata_path):\n    \"\"\"\n    Load arXiv metadata from the JSON file.\n    Args:\n        metadata_path (str): Path to the metadata JSON file.\n    Returns:\n        List[dict]: List of paper metadata.\n    \"\"\"\n    with open(metadata_path, \"r\") as f:\n        metadata = [json.loads(line) for line in f]\n    return metadata\n\n# Step 2.2: Download PDFs from arXiv\ndef download_pdf(paper_id, output_folder):\n    \"\"\"\n    Download a PDF from arXiv using the paper ID.\n    Args:\n        paper_id (str): arXiv paper ID (e.g., \"0001.0001\").\n        output_folder (str): Folder to save the downloaded PDF.\n    Returns:\n        str: Path to the downloaded PDF.\n    \"\"\"\n    pdf_url = f\"https://arxiv.org/pdf/{paper_id}.pdf\"\n    pdf_path = os.path.join(output_folder, f\"{paper_id}.pdf\")\n\n    # Download the PDF\n    response = requests.get(pdf_url)\n    if response.status_code == 200:\n        with open(pdf_path, \"wb\") as f:\n            f.write(response.content)\n        return pdf_path\n    else:\n        print(f\"Failed to download PDF for paper {paper_id}.\")\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:02:40.734081Z","iopub.execute_input":"2025-03-12T11:02:40.734412Z","iopub.status.idle":"2025-03-12T11:02:40.741148Z","shell.execute_reply.started":"2025-03-12T11:02:40.734384Z","shell.execute_reply":"2025-03-12T11:02:40.740261Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Step 2.3: Extract Images from PDFs\ndef extract_images_from_pdf(pdf_path, output_folder):\n    \"\"\"\n    Extract images from a PDF file and save them to the output folder.\n    Args:\n        pdf_path (str): Path to the PDF file.\n        output_folder (str): Folder to save extracted images.\n    Returns:\n        List[str]: List of paths to extracted images.\n    \"\"\"\n    # Open the PDF file\n    pdf_document = fitz.open(pdf_path)\n    image_paths = []\n\n    # Iterate through pages and extract images\n    for page_num in range(len(pdf_document)):\n        page = pdf_document.load_page(page_num)\n        image_list = page.get_images(full=True)\n\n        # Save each image\n        for img_index, img in enumerate(image_list):\n            xref = img[0]\n            base_image = pdf_document.extract_image(xref)\n            image_bytes = base_image[\"image\"]\n            image_ext = base_image[\"ext\"]\n            image_filename = f\"page_{page_num + 1}_img_{img_index + 1}.{image_ext}\"\n            image_path = os.path.join(output_folder, image_filename)\n\n            with open(image_path, \"wb\") as image_file:\n                image_file.write(image_bytes)\n            image_paths.append(image_path)\n\n    return image_paths\n\n# Step 2.4: Generate Image Embeddings Using CLIP\ndef extract_and_embed_images(image_paths):\n    \"\"\"\n    Extract images and generate embeddings using OpenAI's CLIP model.\n    Args:\n        image_paths (List[str]): List of paths to images.\n    Returns:\n        List[torch.Tensor]: List of image embeddings.\n    \"\"\"\n    # Load CLIP model and processor\n    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n    # Process images and generate embeddings\n    image_embeddings = []\n    for image_path in image_paths:\n        image = Image.open(image_path)\n        inputs = clip_processor(images=image, return_tensors=\"pt\", padding=True)\n        with torch.no_grad():\n            image_features = clip_model.get_image_features(**inputs)\n        image_embeddings.append(image_features)\n\n    return image_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:03:04.739403Z","iopub.execute_input":"2025-03-12T11:03:04.739732Z","iopub.status.idle":"2025-03-12T11:03:04.746444Z","shell.execute_reply.started":"2025-03-12T11:03:04.739702Z","shell.execute_reply":"2025-03-12T11:03:04.745599Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Step 2.2: Incorporate Audio/Video Embeddings Using Whisper\ndef transcribe_and_embed_audio(audio_paths):\n    \"\"\"\n    Transcribe audio and generate embeddings for the transcribed text.\n    Args:\n        audio_paths (List[str]): List of paths to audio files.\n    Returns:\n        List[torch.Tensor]: List of text embeddings.\n    \"\"\"\n    # Load Whisper model and processor\n    whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n    whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n\n    # Load text embedding model\n    text_embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n\n    # Transcribe audio and generate embeddings\n    text_embeddings = []\n    for audio_path in audio_paths:\n        # Transcribe audio\n        inputs = whisper_processor.from_pretrained(audio_path, return_tensors=\"pt\", sampling_rate=16000)\n        with torch.no_grad():\n            generated_ids = whisper_model.generate(inputs.input_features)\n        transcription = whisper_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n        # Generate text embeddings\n        embedding = text_embedder.embed_documents([transcription])\n        text_embeddings.append(embedding)\n\n    return text_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:03:09.432192Z","iopub.execute_input":"2025-03-12T11:03:09.432471Z","iopub.status.idle":"2025-03-12T11:03:09.437406Z","shell.execute_reply.started":"2025-03-12T11:03:09.432450Z","shell.execute_reply":"2025-03-12T11:03:09.436535Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Step 2.3: Combine Multimodal Embeddings\ndef combine_multimodal_embeddings(image_embeddings, text_embeddings):\n    \"\"\"\n    Combine image and text embeddings into a unified embedding space.\n    Args:\n        image_embeddings (List[torch.Tensor]): List of image embeddings.\n        text_embeddings (List[torch.Tensor]): List of text embeddings.\n    Returns:\n        List[torch.Tensor]: Combined embeddings.\n    \"\"\"\n    combined_embeddings = []\n    for img_emb, txt_emb in zip(image_embeddings, text_embeddings):\n        # Concatenate image and text embeddings (or use another fusion method)\n        combined_embedding = torch.cat((img_emb, txt_emb), dim=1)\n        combined_embeddings.append(combined_embedding)\n\n    return combined_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:03:12.678324Z","iopub.execute_input":"2025-03-12T11:03:12.678627Z","iopub.status.idle":"2025-03-12T11:03:12.683029Z","shell.execute_reply.started":"2025-03-12T11:03:12.678603Z","shell.execute_reply":"2025-03-12T11:03:12.682037Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Main Execution for Step 2\nif __name__ == \"__main__\":\n    # Paths\n    metadata_path = \"/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json\"  # Path to metadata\n    pdf_output_folder = \"/kaggle/working/pdfs\"  # Folder to save downloaded PDFs\n    image_output_folder = \"/kaggle/working/extracted_images\"  # Folder to save extracted images\n\n    # Create output folders if they don't exist\n    os.makedirs(pdf_output_folder, exist_ok=True)\n    os.makedirs(image_output_folder, exist_ok=True)\n\n    # Step 2.1: Load metadata\n    metadata = load_metadata(metadata_path)\n    print(f\"Loaded metadata for {len(metadata)} papers.\")\n\n    # Step 2.2: Download PDF for the first paper (for demonstration)\n    paper_id = metadata[0][\"id\"]  # Use the first paper in the metadata\n    pdf_path = download_pdf(paper_id, pdf_output_folder)\n\n    if pdf_path:\n        print(f\"Downloaded PDF for paper {paper_id} to {pdf_path}.\")\n\n        # Step 2.3: Extract images from PDF\n        image_paths = extract_images_from_pdf(pdf_path, image_output_folder)\n        print(\"Extracted images:\", image_paths)\n\n        # Step 2.4: Extract and embed images\n        if image_paths:\n            image_embeddings = extract_and_embed_images(image_paths)\n            print(\"Image embeddings generated:\", len(image_embeddings))\n        else:\n            print(\"No images found in the PDF.\")\n    else:\n        print(\"Failed to download PDF.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-12T11:03:17.122075Z","iopub.execute_input":"2025-03-12T11:03:17.122374Z","iopub.status.idle":"2025-03-12T11:05:25.369742Z","shell.execute_reply.started":"2025-03-12T11:03:17.122350Z","shell.execute_reply":"2025-03-12T11:05:25.368660Z"}},"outputs":[{"name":"stdout","text":"Loaded metadata for 2683176 papers.\nDownloaded PDF for paper 0704.0001 to /kaggle/working/pdfs/0704.0001.pdf.\nExtracted images: ['/kaggle/working/extracted_images/page_15_img_1.jpeg']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42ca44d9e6384c85b0e488e9e2e56df6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fceb0f73f0e44299baa51df69ef7921e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3870eb385a6c4c169ab97d6af269e460"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9c6915822954da0b4fa83b1cce2b427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be9064a2bf2e46ce89934f5a61fb4db6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d137d231a3f74ddb940e40d30f9a2330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d466cbdb01415e993c16d63aff72db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026525137c214b01afb5711dd52c4b41"}},"metadata":{}},{"name":"stdout","text":"Image embeddings generated: 1\n","output_type":"stream"}],"execution_count":9}]}